---
title: Theory Behind LLMs
date: "2025-02-23T00:00:00"
type: docs 
weight: 400
menu: 
    llms-hpc:
      parent: Overview of LLMs
---

{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_2.png height=50% width=50% >}}

LLMs are based on the transformer architecture.
We are not covering this in todayâ€™s workshop.

More Information:
  * _[Attention Is All You Need](https://arxiv.org/abs/1706.03762)_ by Vaswani et al. (2017)
  * [https://jalammar.github.io/illustrated-transformer/](https://jalammar.github.io/illustrated-transformer/)


